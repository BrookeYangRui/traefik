#!/usr/bin/env python3
"""
æ£€æŸ¥ GitHub é¡¹ç›®æ˜¯å¦é…ç½®äº† trustedIPs ç™½åå•
å³ä½¿è®¾ç½®äº† insecure: true æˆ– trustForwardHeader: trueï¼Œå¦‚æœæœ‰ç™½åå•ï¼Œé£é™©ä¼šé™ä½
"""

import json
import os
import sys
import re
import requests
from urllib.parse import quote

def get_raw_content_url(github_url):
    """å°† GitHub URL è½¬æ¢ä¸º raw content URL"""
    # https://github.com/user/repo/blob/branch/path/file
    # -> https://raw.githubusercontent.com/user/repo/branch/path/file
    pattern = r'https://github\.com/([^/]+)/([^/]+)/blob/([^/]+)/(.+)'
    match = re.match(pattern, github_url)
    if match:
        user, repo, branch, path = match.groups()
        return f"https://raw.githubusercontent.com/{user}/{repo}/{branch}/{path}"
    return None

def check_config_content(raw_url):
    """æ£€æŸ¥é…ç½®æ–‡ä»¶å†…å®¹ï¼ŒæŸ¥æ‰¾ trustedIPs é…ç½®"""
    try:
        response = requests.get(raw_url, timeout=10)
        if response.status_code == 200:
            content = response.text
            return content
    except Exception as e:
        return None
    return None

def analyze_config(content, file_path):
    """åˆ†æé…ç½®å†…å®¹ï¼ŒæŸ¥æ‰¾å®‰å…¨è®¾ç½®"""
    result = {
        'has_insecure': False,
        'has_trustForwardHeader': False,
        'has_trustedIPs': False,
        'trustedIPs_value': None,
        'is_wide_open': False,
        'risk_level': 'unknown'
    }
    
    content_lower = content.lower()
    
    # æ£€æŸ¥ insecure
    if 'insecure' in content_lower and 'true' in content_lower:
        # æ£€æŸ¥æ˜¯å¦æ˜¯ forwardedHeaders.insecure
        if 'forwardedheaders' in content_lower or 'forwarded_headers' in content_lower:
            result['has_insecure'] = True
    
    # æ£€æŸ¥ trustForwardHeader
    if 'trustforwardheader' in content_lower and 'true' in content_lower:
        result['has_trustForwardHeader'] = True
    
    # æ£€æŸ¥ trustedIPs
    # åŒ¹é…å„ç§æ ¼å¼ï¼štrustedIPs, trustedIPs:, trustedIPs =, etc.
    trusted_ips_patterns = [
        r'trustedIPs\s*[:=]\s*\[(.*?)\]',
        r'trustedIPs\s*[:=]\s*(.*?)(?:\n|$)',
        r'trustedIPs:\s*(.*?)(?:\n|$)',
        r'trustedips\s*[:=]\s*\[(.*?)\]',
    ]
    
    for pattern in trusted_ips_patterns:
        match = re.search(pattern, content, re.IGNORECASE | re.MULTILINE | re.DOTALL)
        if match:
            result['has_trustedIPs'] = True
            ips_value = match.group(1).strip()
            result['trustedIPs_value'] = ips_value
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯è¿‡å®½çš„èŒƒå›´
            if any(wide in ips_value.lower() for wide in ['0.0.0.0', '/0', '*', 'all', 'any']):
                result['is_wide_open'] = True
            break
    
    # è¯„ä¼°é£é™©ç­‰çº§
    if result['has_insecure'] or result['has_trustForwardHeader']:
        if result['has_trustedIPs']:
            if result['is_wide_open']:
                result['risk_level'] = 'high'  # æœ‰ç™½åå•ä½†èŒƒå›´è¿‡å®½
            else:
                result['risk_level'] = 'medium'  # æœ‰ç™½åå•ä¸”èŒƒå›´åˆç†
        else:
            result['risk_level'] = 'high'  # æ²¡æœ‰ç™½åå•
    else:
        result['risk_level'] = 'low'
    
    return result

def analyze_repositories(results_file):
    """åˆ†ææ‰€æœ‰ä»“åº“çš„é…ç½®"""
    
    with open(results_file, 'r') as f:
        results = json.load(f)
    
    print("=" * 80)
    print("æ£€æŸ¥é…ç½®ä¸­çš„ trustedIPs ç™½åå•")
    print("=" * 80)
    print()
    
    analyzed = []
    no_whitelist = []
    has_whitelist = []
    wide_open = []
    
    for i, result in enumerate(results, 1):
        repo_name = result['repository']
        file_path = result['file']
        url = result['url']
        search_type = result['search_type']
        
        print(f"[{i}/{len(results)}] æ£€æŸ¥: {repo_name}/{file_path}")
        
        raw_url = get_raw_content_url(url)
        if not raw_url:
            print(f"  âš ï¸  æ— æ³•è·å– raw URL")
            continue
        
        content = check_config_content(raw_url)
        if not content:
            print(f"  âš ï¸  æ— æ³•è·å–æ–‡ä»¶å†…å®¹")
            continue
        
        analysis = analyze_config(content, file_path)
        analysis['repo'] = repo_name
        analysis['file'] = file_path
        analysis['url'] = url
        analysis['search_type'] = search_type
        analyzed.append(analysis)
        
        # åˆ†ç±»
        if analysis['has_insecure'] or analysis['has_trustForwardHeader']:
            if analysis['has_trustedIPs']:
                if analysis['is_wide_open']:
                    wide_open.append(analysis)
                    print(f"  âš ï¸  æœ‰ç™½åå•ä½†èŒƒå›´è¿‡å®½: {analysis['trustedIPs_value']}")
                else:
                    has_whitelist.append(analysis)
                    print(f"  âœ“ æœ‰ç™½åå•: {analysis['trustedIPs_value'][:50]}...")
            else:
                no_whitelist.append(analysis)
                print(f"  ğŸ”´ æ²¡æœ‰ç™½åå• - é«˜é£é™©ï¼")
        else:
            print(f"  â„¹ï¸  æœªå‘ç°ç›¸å…³é…ç½®")
        
        print()
    
    # ç»Ÿè®¡
    print("=" * 80)
    print("ç»Ÿè®¡ç»“æœ")
    print("=" * 80)
    print()
    
    print(f"æ€»æ£€æŸ¥æ•°: {len(analyzed)}")
    print(f"ğŸ”´ æ²¡æœ‰ç™½åå• (é«˜é£é™©): {len(no_whitelist)}")
    print(f"âš ï¸  æœ‰ç™½åå•ä½†èŒƒå›´è¿‡å®½: {len(wide_open)}")
    print(f"âœ“ æœ‰ç™½åå•ä¸”èŒƒå›´åˆç† (ä¸­ç­‰é£é™©): {len(has_whitelist)}")
    print()
    
    # è¯¦ç»†åˆ—è¡¨
    if no_whitelist:
        print("=" * 80)
        print("ğŸ”´ æ²¡æœ‰ç™½åå•çš„é¡¹ç›® (é«˜é£é™©)")
        print("=" * 80)
        for item in no_whitelist:
            print(f"\nğŸ“¦ {item['repo']}")
            print(f"   æ–‡ä»¶: {item['file']}")
            print(f"   é…ç½®: {item['search_type']}")
            print(f"   URL: {item['url']}")
    
    if wide_open:
        print("\n" + "=" * 80)
        print("âš ï¸  æœ‰ç™½åå•ä½†èŒƒå›´è¿‡å®½çš„é¡¹ç›®")
        print("=" * 80)
        for item in wide_open:
            print(f"\nğŸ“¦ {item['repo']}")
            print(f"   æ–‡ä»¶: {item['file']}")
            print(f"   ç™½åå•: {item['trustedIPs_value']}")
            print(f"   URL: {item['url']}")
    
    if has_whitelist:
        print("\n" + "=" * 80)
        print("âœ“ æœ‰ç™½åå•ä¸”èŒƒå›´åˆç†çš„é¡¹ç›® (é£é™©è¾ƒä½)")
        print("=" * 80)
        for item in has_whitelist:
            print(f"\nğŸ“¦ {item['repo']}")
            print(f"   æ–‡ä»¶: {item['file']}")
            print(f"   ç™½åå•: {item['trustedIPs_value'][:100]}")
            print(f"   URL: {item['url']}")
    
    # ä¿å­˜ç»“æœ
    output = {
        'total': len(analyzed),
        'no_whitelist': len(no_whitelist),
        'wide_open': len(wide_open),
        'has_whitelist': len(has_whitelist),
        'details': {
            'no_whitelist': no_whitelist,
            'wide_open': wide_open,
            'has_whitelist': has_whitelist
        }
    }
    
    output_file = results_file.replace('.json', '_whitelist_analysis.json')
    with open(output_file, 'w') as f:
        json.dump(output, f, indent=2)
    
    print(f"\nç»“æœå·²ä¿å­˜åˆ°: {output_file}")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        # æŸ¥æ‰¾æœ€æ–°çš„ç»“æœæ–‡ä»¶
        results_dir = os.path.join(os.path.dirname(__file__), '../../results')
        json_files = [f for f in os.listdir(results_dir) if f.startswith('traefik_github_results_') and f.endswith('.json')]
        if json_files:
            latest = max(json_files, key=lambda f: os.path.getctime(os.path.join(results_dir, f)))
            results_file = os.path.join(results_dir, latest)
            print(f"ä½¿ç”¨æœ€æ–°çš„ç»“æœæ–‡ä»¶: {latest}")
        else:
            print("é”™è¯¯: æœªæ‰¾åˆ°ç»“æœæ–‡ä»¶")
            print("ç”¨æ³•: python3 check_trusted_ips.py <results_file.json>")
            sys.exit(1)
    else:
        results_file = sys.argv[1]
    
    analyze_repositories(results_file)

