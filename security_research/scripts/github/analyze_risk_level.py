#!/usr/bin/env python3
"""
åˆ†æ GitHub æœç´¢ç»“æœçš„é£é™©ç­‰çº§å’Œé¡¹ç›®ä¿¡æ¯
"""

import json
import os
import sys
from datetime import datetime

try:
    from github import Github
except ImportError:
    print("é”™è¯¯: éœ€è¦å®‰è£… pygithub")
    print("å®‰è£…: pip install pygithub")
    sys.exit(1)

def get_token():
    """è·å– GitHub token"""
    token = os.getenv('GITHUB_TOKEN')
    if not token:
        # å°è¯•ä»æ–‡ä»¶è¯»å–
        possible_paths = [
            os.path.join(os.path.dirname(__file__), '../../config/.github_token'),
            os.path.join(os.path.dirname(__file__), '.github_token'),
            '.github_token',
        ]
        for path in possible_paths:
            if os.path.exists(path):
                with open(path, 'r') as f:
                    token = f.read().strip()
                    break
    return token

def analyze_repositories(results_file):
    """åˆ†æä»“åº“çš„é£é™©ç­‰çº§å’Œé¡¹ç›®ä¿¡æ¯"""
    
    token = get_token()
    if not token:
        print("é”™è¯¯: éœ€è¦ GitHub token")
        return
    
    g = Github(token)
    
    with open(results_file, 'r') as f:
        results = json.load(f)
    
    print("=" * 80)
    print("GitHub æœç´¢ç»“æœé£é™©åˆ†æ")
    print("=" * 80)
    print()
    
    # æŒ‰é£é™©ç±»å‹åˆ†ç±»
    risk_categories = {
        "ğŸ”´ é«˜é£é™©": [],
        "âš ï¸  ä¸­ç­‰é£é™©": [],
        "â„¹ï¸  ä½é£é™©/ç¤ºä¾‹": []
    }
    
    analyzed_repos = {}
    
    for result in results:
        repo_name = result['repository']
        search_type = result['search_type']
        file_path = result['file']
        url = result['url']
        
        # åˆ¤æ–­é£é™©ç­‰çº§
        if "insecure: true" in search_type:
            risk_level = "ğŸ”´ é«˜é£é™©"
        elif "trustForwardHeader" in search_type:
            risk_level = "âš ï¸  ä¸­ç­‰é£é™©"
        else:
            risk_level = "â„¹ï¸  ä½é£é™©/ç¤ºä¾‹"
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç¤ºä¾‹/æµ‹è¯•æ–‡ä»¶
        if any(keyword in file_path.lower() for keyword in ['example', 'sample', 'test', 'fixture', 'demo', 'template']):
            risk_level = "â„¹ï¸  ä½é£é™©/ç¤ºä¾‹"
        
        # è·å–ä»“åº“ä¿¡æ¯
        if repo_name not in analyzed_repos:
            try:
                repo = g.get_repo(repo_name)
                analyzed_repos[repo_name] = {
                    'repo': repo,
                    'stars': repo.stargazers_count,
                    'forks': repo.forks_count,
                    'updated': repo.updated_at,
                    'is_archived': repo.archived,
                    'is_private': repo.private,
                    'language': repo.language,
                    'description': repo.description
                }
            except Exception as e:
                analyzed_repos[repo_name] = {
                    'error': str(e),
                    'stars': 0
                }
        
        repo_info = analyzed_repos[repo_name]
        
        risk_categories[risk_level].append({
            'repo': repo_name,
            'file': file_path,
            'url': url,
            'search_type': search_type,
            'stars': repo_info.get('stars', 0),
            'forks': repo_info.get('forks', 0),
            'updated': repo_info.get('updated'),
            'is_archived': repo_info.get('is_archived', False),
            'language': repo_info.get('language'),
            'description': repo_info.get('description', '')
        })
    
    # è¾“å‡ºåˆ†æç»“æœ
    for risk_level, items in risk_categories.items():
        if not items:
            continue
        
        print(f"\n{risk_level} ({len(items)} ä¸ª)")
        print("-" * 80)
        
        # æŒ‰ star æ•°æ’åº
        items.sort(key=lambda x: x['stars'], reverse=True)
        
        for item in items:
            repo_name = item['repo']
            stars = item['stars']
            forks = item.get('forks', 0)
            updated = item.get('updated')
            is_archived = item.get('is_archived', False)
            language = item.get('language', 'N/A')
            
            # åˆ¤æ–­æ˜¯å¦çœŸçš„æœ‰é—®é¢˜
            is_example = any(kw in item['file'].lower() for kw in ['example', 'sample', 'test', 'fixture', 'demo'])
            is_official = 'traefik/traefik' in repo_name
            
            status = ""
            if is_example:
                status = " [ç¤ºä¾‹/æµ‹è¯•æ–‡ä»¶]"
            elif is_official:
                status = " [å®˜æ–¹é¡¹ç›®]"
            elif is_archived:
                status = " [å·²å½’æ¡£]"
            
            print(f"\nğŸ“¦ {repo_name}")
            print(f"   â­ Stars: {stars:,} | ğŸ´ Forks: {forks:,} | ğŸ“ Language: {language}")
            if updated:
                print(f"   ğŸ“… æœ€åæ›´æ–°: {updated.strftime('%Y-%m-%d')}")
            print(f"   ğŸ“„ æ–‡ä»¶: {item['file']}")
            print(f"   ğŸ”— URL: {item['url']}")
            print(f"   ğŸ“Š é£é™©ç±»å‹: {item['search_type']}")
            if status:
                print(f"   â„¹ï¸  {status}")
            
            # è¯„ä¼°å®é™…é£é™©
            if is_example or is_official:
                print(f"   âš ï¸  è¯„ä¼°: å¯èƒ½æ˜¯ç¤ºä¾‹/æµ‹è¯•æ–‡ä»¶ï¼Œå®é™…é£é™©è¾ƒä½")
            elif stars > 100:
                print(f"   âš ï¸  è¯„ä¼°: é«˜æ˜Ÿé¡¹ç›®ï¼Œå¯èƒ½åœ¨ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ï¼Œéœ€è¦å…³æ³¨")
            elif stars > 10:
                print(f"   âš ï¸  è¯„ä¼°: ä¸­ç­‰æ´»è·ƒåº¦é¡¹ç›®ï¼Œéœ€è¦è¿›ä¸€æ­¥éªŒè¯")
            else:
                print(f"   âš ï¸  è¯„ä¼°: ä½æ´»è·ƒåº¦é¡¹ç›®ï¼Œå¯èƒ½æ˜¯ä¸ªäººé¡¹ç›®")
    
    # ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 80)
    print("ç»Ÿè®¡ä¿¡æ¯")
    print("=" * 80)
    
    total_stars = sum(item['stars'] for items in risk_categories.values() for item in items)
    high_star_repos = [item for items in risk_categories.values() for item in items if item['stars'] > 100]
    official_repos = [item for items in risk_categories.values() for item in items if 'traefik/traefik' in item['repo']]
    example_files = [item for items in risk_categories.values() for item in items if any(kw in item['file'].lower() for kw in ['example', 'sample', 'test', 'fixture'])]
    
    print(f"\næ€»é¡¹ç›®æ•°: {len(analyzed_repos)}")
    print(f"æ€» Star æ•°: {total_stars:,}")
    print(f"é«˜æ˜Ÿé¡¹ç›® (>100 stars): {len(high_star_repos)}")
    print(f"å®˜æ–¹é¡¹ç›®: {len(official_repos)}")
    print(f"ç¤ºä¾‹/æµ‹è¯•æ–‡ä»¶: {len(example_files)}")
    
    # çœŸæ­£æœ‰é£é™©çš„é¡¹ç›®
    real_risk = [item for items in risk_categories["ğŸ”´ é«˜é£é™©"] + risk_categories["âš ï¸  ä¸­ç­‰é£é™©"] 
                 for item in items 
                 if not any(kw in item['file'].lower() for kw in ['example', 'sample', 'test', 'fixture', 'demo'])
                 and 'traefik/traefik' not in item['repo']
                 and item['stars'] > 0]
    
    print(f"\nâš ï¸  çœŸæ­£éœ€è¦å…³æ³¨çš„é¡¹ç›®: {len(real_risk)}")
    print("   (æ’é™¤ç¤ºä¾‹æ–‡ä»¶ã€å®˜æ–¹é¡¹ç›®å’Œ 0 star é¡¹ç›®)")
    
    if real_risk:
        print("\néœ€è¦é‡ç‚¹å…³æ³¨çš„é¡¹ç›®:")
        for item in sorted(real_risk, key=lambda x: x['stars'], reverse=True)[:10]:
            print(f"  - {item['repo']} ({item['stars']} stars) - {item['file']}")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        # æŸ¥æ‰¾æœ€æ–°çš„ç»“æœæ–‡ä»¶
        results_dir = os.path.join(os.path.dirname(__file__), '../../results')
        json_files = [f for f in os.listdir(results_dir) if f.startswith('traefik_github_results_') and f.endswith('.json')]
        if json_files:
            latest = max(json_files, key=lambda f: os.path.getctime(os.path.join(results_dir, f)))
            results_file = os.path.join(results_dir, latest)
            print(f"ä½¿ç”¨æœ€æ–°çš„ç»“æœæ–‡ä»¶: {latest}")
        else:
            print("é”™è¯¯: æœªæ‰¾åˆ°ç»“æœæ–‡ä»¶")
            print("ç”¨æ³•: python3 analyze_risk_level.py <results_file.json>")
            sys.exit(1)
    else:
        results_file = sys.argv[1]
    
    analyze_repositories(results_file)

